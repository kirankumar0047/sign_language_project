Sign Language Recognition System

This project is a real-time Sign Language Recognition system that uses a Convolutional Neural Network (CNN) model trained on the ASL Alphabet dataset to recognize hand gestures from a webcam feed.

ğŸ“ Project Structure

sign_language_project/
â”œâ”€â”€ dataset/
â”‚   â””â”€â”€ asl_alphabet_train/   # Aâ€“Z folders with hand sign images
â”œâ”€â”€ model/
â”‚   â””â”€â”€ sign_model.h5         # Trained CNN model
â”œâ”€â”€ train_model.py            # Script to train the model
â”œâ”€â”€ main.py                   # Real-time prediction using webcam
â”œâ”€â”€ requirements.txt          # List of dependencies
â””â”€â”€ README.md                 # Project overview


Features:
- Detects American Sign Language (Aâ€“Z) in real-time using webcam
- Uses a custom-trained CNN model
- Predicts and displays the detected sign with confidence
- Fast and efficient model with option to improve accuracy
- Modular code (training and inference separated)


Requirements:
Install required Python packages using:
pip install -r requirements.txt

Dependencies include:
	â€¢	tensorflow
	â€¢	opencv-python
	â€¢	numpy

How It Works? 
Training:
	â€¢	Run train_model.py to train the model on dataset/asl_alphabet_train/
	â€¢	Model is saved to model/sign_model.h5
Real-Time Prediction:
	â€¢	Run main.py to start webcam-based detection
	â€¢	A green box will appear â€” show your sign inside that box
	â€¢	The model will predict the sign and display it with confidence
 
Train the model:
python train_model.py

Run real-time detection:
python main.py
